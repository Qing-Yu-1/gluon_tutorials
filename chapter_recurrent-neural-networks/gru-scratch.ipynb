{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 门控循环单元（GRU）--- 从0开始\n",
    "\n",
    "[上一节](bptt.md)中，我们介绍了循环神经网络中的梯度计算方法。我们发现，循环神经网络的隐含层变量梯度可能会出现衰减或爆炸。虽然[梯度裁剪](rnn-scratch.md)可以应对梯度爆炸，但无法解决梯度衰减的问题。因此，给定一个时间序列，例如文本序列，循环神经网络在实际中其实较难捕捉两个时刻距离较大的文本元素（字或词）之间的依赖关系。\n",
    "\n",
    "门控循环神经网络（gated recurrent neural networks）的提出，是为了更好地捕捉时序数据中间隔较大的依赖关系。其中，门控循环单元（gated recurrent unit，简称GRU）是一种常用的门控循环神经网络。它由Cho、van Merrienboer、 Bahdanau和Bengio在2014年被提出。\n",
    "\n",
    "\n",
    "## 门控循环单元\n",
    "\n",
    "我们先介绍门控循环单元的构造。它比循环神经网络中的隐含层构造稍复杂一点。\n",
    "\n",
    "### 重置门和更新门\n",
    "\n",
    "门控循环单元的隐含状态只包含隐含层变量$\\mathbf{H}$。假定隐含状态长度为$h$，给定时刻$t$的一个样本数为$n$特征向量维度为$x$的批量数据$\\mathbf{X}_t \\in \\mathbb{R}^{n \\times x}$和上一时刻隐含状态$\\mathbf{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$，重置门（reset gate）$\\mathbf{R}_t \\in \\mathbb{R}^{n \\times h}$和更新门（update gate）$\\mathbf{Z}_t \\in \\mathbb{R}^{n \\times h}$的定义如下：\n",
    "\n",
    "$$\\mathbf{R}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xr} + \\mathbf{H}_{t-1} \\mathbf{W}_{hr} + \\mathbf{b}_r)$$\n",
    "\n",
    "$$\\mathbf{Z}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xz} + \\mathbf{H}_{t-1} \\mathbf{W}_{hz} + \\mathbf{b}_z)$$\n",
    "\n",
    "其中的$\\mathbf{W}_{xr}, \\mathbf{W}_{xz} \\in \\mathbb{R}^{x \\times h}$和$\\mathbf{W}_{hr}, \\mathbf{W}_{hz} \\in \\mathbb{R}^{h \\times h}$是可学习的权重参数，$\\mathbf{b}_r, \\mathbf{b}_z \\in \\mathbb{R}^{1 \\times h}$是可学习的偏移参数。函数$\\sigma$自变量中的三项相加使用了[广播](../chapter_crashcourse/ndarray.md)。\n",
    "\n",
    "需要注意的是，重置门和更新门使用了值域为$[0, 1]$的函数$\\sigma(x) = 1/(1+\\text{exp}(-x))$。因此，重置门$\\mathbf{R}_t$和更新门$\\mathbf{Z}_t$中每个元素的值域都是$[0, 1]$。\n",
    "\n",
    "\n",
    "### 候选隐含状态\n",
    "\n",
    "我们可以通过元素值域在$[0, 1]$的更新门和重置门来控制隐含状态中信息的流动：这通常可以应用按元素乘法符$\\odot$。门控循环单元中的候选隐含状态$\\tilde{\\mathbf{H}}_t \\in \\mathbb{R}^{n \\times h}$使用了值域在$[-1, 1]$的双曲正切函数tanh做激活函数：\n",
    "\n",
    "$$\\tilde{\\mathbf{H}}_t = \\text{tanh}(\\mathbf{X}_t \\mathbf{W}_{xh} + \\mathbf{R}_t \\odot \\mathbf{H}_{t-1} \\mathbf{W}_{hh} + \\mathbf{b}_h)$$\n",
    "\n",
    "其中的$\\mathbf{W}_{xh} \\in \\mathbb{R}^{x \\times h}$和$\\mathbf{W}_{hh} \\in \\mathbb{R}^{h \\times h}$是可学习的权重参数，$\\mathbf{b}_h \\in \\mathbb{R}^{1 \\times h}$是可学习的偏移参数。\n",
    "\n",
    "需要注意的是，候选隐含状态使用了重置门来控制包含过去时刻信息的上一个隐含状态的流入。如果重置门近似0，上一个隐含状态将被丢弃。因此，重置门提供了丢弃与未来无关的过去隐含状态的机制。\n",
    "\n",
    "\n",
    "### 隐含状态\n",
    "\n",
    "隐含状态$\\mathbf{H}_t \\in \\mathbb{R}^{n \\times h}$的计算使用更新门$\\mathbf{Z}_t$来对上一时刻的隐含状态$\\mathbf{H}_{t-1}$和当前时刻的候选隐含状态$\\tilde{\\mathbf{H}}_t$做组合，公式如下：\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{Z}_t \\odot \\mathbf{H}_{t-1}  + (1 - \\mathbf{Z}_t) \\odot \\tilde{\\mathbf{H}}_t$$\n",
    "\n",
    "需要注意的是，更新门可以控制过去的隐含状态在当前时刻的重要性。如果更新门一直近似1，过去的隐含状态将一直通过时间保存并传递至当前时刻。这个设计可以应对循环神经网络中的梯度衰减问题，并更好地捕捉时序数据中间隔较大的依赖关系。\n",
    "\n",
    "我们对门控循环单元的设计稍作总结：\n",
    "\n",
    "* 重置门有助于捕捉时序数据中短期的依赖关系。\n",
    "* 更新门有助于捕捉时序数据中长期的依赖关系。\n",
    "\n",
    "\n",
    "输出层的设计可参照[循环神经网络](rnn-scratch.md)中的描述。\n",
    "\n",
    "\n",
    "## 实验\n",
    "\n",
    "\n",
    "为了实现并展示门控循环单元，我们依然使用周杰伦歌词数据集来训练模型作词。这里除门控循环单元以外的实现已在[循环神经网络](rnn-scratch.md)中介绍。\n",
    "\n",
    "\n",
    "### 数据处理\n",
    "\n",
    "我们先读取并对数据集做简单处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 1465\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('../data/jaychou_lyrics.txt.zip', 'r') as zin:\n",
    "    zin.extractall('../data/')\n",
    "\n",
    "with open('../data/jaychou_lyrics.txt') as f:\n",
    "    corpus_chars = f.read()\n",
    "\n",
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "corpus_chars = corpus_chars[0:20000]\n",
    "\n",
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print('vocab size:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用onehot来将字符索引表示成向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "def get_inputs(data):\n",
    "    return [nd.one_hot(X, vocab_size) for X in data.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数\n",
    "\n",
    "以下部分对模型参数进行初始化。参数`hidden_dim`定义了隐含状态的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use gpu(0)\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# 尝试使用GPU\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from mxnet import nd\n",
    "import utils\n",
    "ctx = utils.try_gpu()\n",
    "print('Will use', ctx)\n",
    "\n",
    "input_dim = vocab_size\n",
    "# 隐含状态长度\n",
    "hidden_dim = 256\n",
    "output_dim = vocab_size\n",
    "std = .01\n",
    "\n",
    "def get_params():\n",
    "    # 隐含层\n",
    "    W_xz = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hz = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_z = nd.zeros(hidden_dim, ctx=ctx)\n",
    "    \n",
    "    W_xr = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hr = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_r = nd.zeros(hidden_dim, ctx=ctx)\n",
    "\n",
    "    W_xh = nd.random_normal(scale=std, shape=(input_dim, hidden_dim), ctx=ctx)\n",
    "    W_hh = nd.random_normal(scale=std, shape=(hidden_dim, hidden_dim), ctx=ctx)\n",
    "    b_h = nd.zeros(hidden_dim, ctx=ctx)\n",
    "\n",
    "    # 输出层\n",
    "    W_hy = nd.random_normal(scale=std, shape=(hidden_dim, output_dim), ctx=ctx)\n",
    "    b_y = nd.zeros(output_dim, ctx=ctx)\n",
    "\n",
    "    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hy, b_y]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "我们将前面的模型公式翻译成代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "def gru_rnn(inputs, H, *params):\n",
    "    # inputs: num_steps 个尺寸为 batch_size * vocab_size 矩阵\n",
    "    # H: 尺寸为 batch_size * hidden_dim 矩阵\n",
    "    # outputs: num_steps 个尺寸为 batch_size * vocab_size 矩阵\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hy, b_y = params\n",
    "    outputs = []\n",
    "    for X in inputs:        \n",
    "        Z = nd.sigmoid(nd.dot(X, W_xz) + nd.dot(H, W_hz) + b_z)\n",
    "        R = nd.sigmoid(nd.dot(X, W_xr) + nd.dot(H, W_hr) + b_r)\n",
    "        H_tilda = nd.tanh(nd.dot(X, W_xh) + R * nd.dot(H, W_hh) + b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        Y = nd.dot(H, W_hy) + b_y\n",
    "        outputs.append(Y)\n",
    "    return (outputs, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "下面我们开始训练模型。我们假定谱写歌词的前缀分别为“分开”、“不分开”和“战争中部队”。这里采用的是相邻批量采样实验门控循环单元谱写歌词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20. Training perplexity 274.548603\n",
      " -  分开 我不的我的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开 我不的我的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你\n",
      " -  战争中部队 我不的我的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你的我的你\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40. Training perplexity 104.648458\n",
      " -  分开 我想要你的爱你 爱不能 我不要 别不是我想要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开 我不要你的爱你 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你\n",
      " -  战争中部队 我想你的爱你 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的爱爱 我不要你的\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60. Training perplexity 28.327697\n",
      " -  分开 不知不觉 我不了这样 我不要 你不是我想要 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开 我不能再想 我不能再想 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我\n",
      " -  战争中部队 我不能再想 我不能再想 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80. Training perplexity 7.650763\n",
      " -  分开 这天事 他的手 有一种热霜 老色蜡烛 我想好好生 我知了好生 我知了好生 你在那里 快给我抬起头 有话去对医药箱说 别怪我 别怪我 说你怎么面对我 甩开球我满腔的怒火 我想揍你已经很久 别想躲 说你眼\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开了你看着好  我知道这里很美 但身为我 你离我 别数球 什么却停 恨不止尽的战争 让我们 半兽人 的灵魂 单纯 停止忿存在的街 用谦卑的旧 有一种味道叫做家 陆羽泡的茶 像幅泼墨的山水画 唐朝千年的风沙\n",
      " -  战争中部队 没有你的手 听一种味道叫做家 陆羽泡的茶 像幅泼墨的山水画 唐朝千年的风沙 现在还在刮 不着你那得 我想要你的微笑 我想要你的表笑 想要你 你爱我 别不来 我想 这不是 的灵魂 单纯 停止忿存 永无止\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100. Training perplexity 2.957180\n",
      " -  分开了这样的我 想要你的爱写的西元前 深埋在美索不达米亚平原 用楔形文纪刻下的誓言 我有一步一步往上的将萨琳缓著 Ch 失A 征ㄡ ㄈㄚ ㄇー xi xi xi xi xi xi xi xi xi xi x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开了你要要过得 不再再来我已无处可躲 我不要再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处可躲 我不要再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受\n",
      " -  战争中部队 没有你在我给大 当水逐　梦的背 我会一直好好过 你已经远远离开 我也会慢慢走开 为什么我连分开都迁就着你 我真的没有天份 安静的没这么快 我会学着放弃你 是因为我太爱你 是因为我太爱你 是因为我太爱你\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120. Training perplexity 1.630590\n",
      " -  分开了注戏就这样) (许ou） 如果我遇见你是一场悲剧 我想我这辈子注定一个人演戏 最后再一个人慢慢的回忆 没有了过去 我将往事抽离 如果我遇见你是一场悲剧 我想我这辈子注定一个人演戏 最后再一个人慢慢的回\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开多出 我要就能放弃 对你依依不舍 连隔壁邻居都猜到我现在的感受 河边的风 在吹着头发飘动 牵着你的手 一阵莫名感动 我想带你 回我的外婆家 一起看着日落 一直到我们都睡着 我想就这样牵着你的手不放开 爱\n",
      " -  战争中部队 没有你手的画 我说你一直牵想 你已经然了离开 我也会慢慢走开 为什么我连分开都迁就着你 我真的没有天份 安静的没这么快 我会学着放弃你 是因为我太爱你 是因为我太爱你 蜗因  <F酸nt 有这样的想知\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140. Training perplexity 1.205914\n",
      " -  分开了 为什么我环分友 从说就是你 笑不再逃睡 雨望都是你说我妈烦你会分道 过难你陪着我 也只是曾经 希望他是真的比我还要爱你 我才会逼自己离开 你要我说多难堪 我根本不想分开 为什么还要我用微笑来带过 我\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开了你就要过得 他不想再多离 我不要再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处可躲 我不要再想 我不要再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处\n",
      " -  战争中部队止) 想回到过去 试着让你在怀里 羞怯的脸带你 快烁检对地更紧 这样挽留不知还来不来得及 想回到过去 思绪不断阻挡着回忆播放 盲目习　不起阻止你身 但说偏大渐渐流到我 你终于还是开了口 小心翼翼的将你的\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160. Training perplexity 1.089089\n",
      " -  分开了 争这样的出球 让我莹 你来我的爱膀 我爱悔 你怎么抄了手 周杰伦 - 简单爱 说不上为什么 我变得很主动 若爱上一个人 什么都会值得去做 我想大声宣布 对你依依不舍 连隔壁邻居都猜到我现在的感受 河\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开多 我手不再你 他的手应该比我更暖 铁盒的序变成了日记 变成了空气 演化成回忆 印象中的爱情好像顶不住那时间 所以你弃权 所以你弃权 我想要的想做的你比谁都了  你想说的想给的我全都知道 未接来电没留言\n",
      " -  战争中部队于它的战 蒙经沙雕的真不好 是谁的黑 在吹着头发飘动 牵着你的手 一阵莫名感动 我想带你 回我的外婆家 一起看着日落 一直到我们都睡着 我想就这样牵着你的手不放开 爱能不能够永远单纯没有悲哀 我 想带你\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180. Training perplexity 1.057499\n",
      " -  分开了 为什么我怎么天 当时走 一步心步我 有物得很主忧 长经 失事的玩妈 你在  笑常常了陪我 说散 你想 这不吗 的灵魂 单纯 对远古存在的神 用谦卑的身份 走廊灯关上 书包放 走到房间窗外望 回想刚买\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开就走 把手慢慢交给我 放下心中的困惑 雨点从两旁划过 割开两种精神的我 经过老伯的家 篮框变得好高 爬过的那棵树 又何时变得渺小 这样也好 开始没人注意到你我 等雨变强之前 我们将会分化软弱 趁时间没发\n",
      " -  战争中部队抢) 穿许云层 就是那扑满 也知道我 相场球 说变的香 我都有谁二 我的世口 相默的假明 让我讲 风脚常的我说 回忆吉柔的路物 维原纯白的象征 然后还原为人 让我们 半兽人 的灵魂 翻滚 收起残忍 回忆\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200. Training perplexity 1.044481\n",
      " -  分开了 为这样的是活 一直吉白 在人里的话隐面一回忆 爷爷泡的茶 有一种味道叫做家 没法挑剔它 口感味觉还不差 陆羽泡的茶 听说名和利都不拿 他牵着一匹瘦马在走天涯 爷爷泡的茶 有一种味道叫做家 他满头白发\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -  不分开就走 把手慢慢交给我 放下心中的困惑 雨点从两旁划过 割开两种精神的我 经过老伯的家 篮框变得好高 爬过的那棵树 又何时变得渺小 这样也好 开始没人注意到我 等雨变强之前 我们将会分化软弱 趁时间没发觉\n",
      " -  战争中部队 没人帮没有你在走 还感动觉来穿历 不曾搁来来巢看历边 为啥咪铁支路直直 火车叨位去 为啥咪铁支路直直 火车叨位去 为啥咪铁支路直直 火车叨位去 车过山洞变成 暗瞑 车过山洞变成 暗瞑 但是连咪都ㄟ 但\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq1 = '分开'\n",
    "seq2 = '不分开'\n",
    "seq3 = '战争中部队'\n",
    "seqs = [seq1, seq2, seq3]\n",
    "\n",
    "utils.train_and_predict_rnn(rnn=gru_rnn, is_random_iter=False, epochs=200,\n",
    "                            num_steps=35, hidden_dim=hidden_dim, \n",
    "                            learning_rate=0.2, clipping_norm=5,\n",
    "                            batch_size=32, pred_period=20, pred_len=100,\n",
    "                            seqs=seqs, get_params=get_params,\n",
    "                            get_inputs=get_inputs, ctx=ctx,\n",
    "                            corpus_indices=corpus_indices,\n",
    "                            idx_to_char=idx_to_char, char_to_idx=char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到一开始学到简单的字符，然后简单的词，接着是复杂点的词，然后看上去似乎像个句子了。\n",
    "\n",
    "## 结论\n",
    "\n",
    "* 门控循环单元的提出是为了更好地捕捉时序数据中间隔较大的依赖关系。\n",
    "* 重置门有助于捕捉时序数据中短期的依赖关系。\n",
    "* 更新门有助于捕捉时序数据中长期的依赖关系。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 调调参数（例如数据集大小、序列长度、隐含状态长度和学习率），看看对运行时间、perplexity和预测的结果造成的影响。\n",
    "* 在相同条件下，比较门控循环单元和循环神经网络的运行效率。\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/4042)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}